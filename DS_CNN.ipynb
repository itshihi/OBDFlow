{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1o_Qz6BoxPMEyK0O2d0dvktVgjJFjxwZf",
      "authorship_tag": "ABX9TyMn5vyfdvRlRuirz5d/a3ns",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itshihi/OBDFlow/blob/main/DS_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "T04kmQQYSQzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DSCNNWithDownsampling(nn.Module):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super(DSCNNWithDownsampling, self).__init__()\n",
        "\n",
        "        # --- Block 1 (64 channels, 32x32) ---\n",
        "        # 크기 변화 없음\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=2, padding=1, groups=in_channels, bias=False),\n",
        "            nn.BatchNorm2d(in_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels, 64, kernel_size=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # --- Block 2 (128 channels, 16x16) ---\n",
        "        # stride=2를 통해 크기를 절반으로 줄임\n",
        "        self.block2 = nn.Sequential(\n",
        "            # Depthwise Conv에서 stride=2로 설정하여 Downsampling 수행!\n",
        "            nn.Conv2d(64, 64, kernel_size=3,stride=2, padding=1, groups=64, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            # Pointwise Conv에서 채널 수를 128로 변경\n",
        "            nn.Conv2d(64, 128, kernel_size=1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # --- Block 3 (128 channels, 8x8) ---\n",
        "        # Conv 연산 후 Max Pooling으로 크기를 절반으로 줄임\n",
        "        self.block3 = nn.Sequential(\n",
        "            # 여기서는 Conv의 stride는 1 (크기 유지)\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1, stride=2,groups=128, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 128, kernel_size=1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            # # Max Pooling 레이어를 추가하여 Downsampling\n",
        "            # nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        # --- 후처리 레이어 ---\n",
        "        self.avgpool = nn.AdaptiveMaxPool2d((1, 1))\n",
        "        self.fc = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        print(f\"Initial shape: \\t{x.shape}\")\n",
        "\n",
        "        x = self.block1(x)\n",
        "        print(f\"After Block 1: \\t{x.shape}\") # [batch, 64, 32, 32]\n",
        "\n",
        "        x = self.block2(x)\n",
        "        print(f\"After Block 2: \\t{x.shape}\") # [batch, 128, 16, 16]\n",
        "\n",
        "        x = self.block3(x)\n",
        "        print(f\"After Block 3: \\t{x.shape}\") # [batch, 128, 8, 8]\n",
        "\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        print(f\"After AVGPool: \\t{x.shape}\") # [batch, 128, 1, 1]\n",
        "\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "        print(f\"After FCL: \\t{x.shape}\") # [batch, 128, 1, 1]\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "kqF53JHjSCrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nA2QjGv3R-bY",
        "outputId": "ef2f995b-118c-4826-cb62-f2f1a56368ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DSCNNWithDownsampling(\n",
            "  (block1): Sequential(\n",
            "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU()\n",
            "  )\n",
            "  (block2): Sequential(\n",
            "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU()\n",
            "  )\n",
            "  (block3): Sequential(\n",
            "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
            "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU()\n",
            "  )\n",
            "  (avgpool): AdaptiveMaxPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n",
            "Initial shape: \ttorch.Size([1, 64, 64, 64])\n",
            "After Block 1: \ttorch.Size([1, 64, 32, 32])\n",
            "After Block 2: \ttorch.Size([1, 128, 16, 16])\n",
            "After Block 3: \ttorch.Size([1, 128, 8, 8])\n",
            "After AVGPool: \ttorch.Size([1, 128, 1, 1])\n",
            "After FCL: \ttorch.Size([1, 10])\n",
            "\n",
            "Final output shape: torch.Size([1, 10])\n"
          ]
        }
      ],
      "source": [
        "# --- 모델 생성 및 테스트 ---\n",
        "model = DSCNNWithDownsampling(in_channels=64, num_classes=8)\n",
        "print(model)\n",
        "dummy_input = torch.randn(1, 64, 64, 64) # 입력 이미지 크기 32x32\n",
        "output = model(dummy_input)\n",
        "\n",
        "print(f\"\\nFinal output shape: {output.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "nNM1kas9SplZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rawdata = pd.read_csv('./drive/MyDrive/1_data_with_weather/data_with_weather.csv')\n",
        "rawdata.head()\n",
        "\n",
        "raw_time_series_data = rawdata\n",
        "raw_time_series_data.set_index('timestamp')\n",
        "\n",
        "print(f\"원본 데이터 shape: {raw_time_series_data.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAqP33uDjhfA",
        "outputId": "88e14364-3e59-4380-ba32-f6f611bdde04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "원본 데이터 shape: (3031, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "OlebKkxJvs4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. 하이퍼파라미터 정의 ---\n",
        "window_size = 128      # 한 번에 볼 데이터의 길이 (시간 스텝)\n",
        "step_size = 64         # 윈도우를 다음으로 이동시킬 칸 수\n",
        "num_features = 16      # 피처(센서 채널)의 개수\n",
        "\n",
        "# --- 2. 입력 데이터 준비 (가상 데이터 생성) ---\n",
        "print(\"--- 데이터 준비 ---\")\n",
        "# 10000개의 시간 스텝을 가진 16개 피처의 시계열 데이터 생성\n",
        "# raw_time_series_data = np.random.randn(10000, num_features)\n",
        "# 각 시간 스텝에 해당하는 레이블 생성 (0, 1, 2 중 하나)\n",
        "# labels = np.random.randint(0, 3, size=(10000,))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# --- 3. 슬라이딩 윈도우를 이용한 데이터 분할 ---\n",
        "print(\"--- 슬라이딩 윈도우 적용 ---\")\n",
        "segments = []\n",
        "segment_labels = []\n",
        "\n",
        "for i in range(0, len(raw_time_series_data) - window_size, step_size):\n",
        "    # 현재 위치에서 window_size 만큼의 데이터 조각을 추출\n",
        "    # Pytorch Conv2d는 (채널, 높이, 너비) 순서를 선호하므로 (피처, 시간) 순으로 저장\n",
        "    current_segment = raw_time_series_data[i : i + window_size].T # .T로 축을 바꿔 (16, 128) 형태로 저장\n",
        "    segments.append(current_segment)\n",
        "\n",
        "    # 해당 조각의 레이블 결정 (윈도우의 마지막 시점 레이블 사용)\n",
        "    current_label = labels[i + window_size - 1]\n",
        "    segment_labels.append(current_label)\n",
        "\n",
        "# 리스트를 numpy 배열로 변환\n",
        "X = np.array(segments)\n",
        "y = np.array(segment_labels)\n",
        "print(f\"분할된 데이터 shape (X): {X.shape}\") # (샘플 수, 피처 수, 윈도우 크기)\n",
        "print(f\"분할된 레이블 shape (y): {y.shape}\\n\")\n",
        "\n",
        "\n",
        "# --- 4. 데이터셋 분리 및 정규화 ---\n",
        "print(\"--- 데이터셋 분리 및 정규화 ---\")\n",
        "# 1. 학습/테스트 데이터 분리 (85% 학습+검증, 15% 테스트)\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
        "# 2. 학습/검증 데이터 분리 (70% 학습, 15% 검증)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=(0.15/0.85), random_state=42)\n",
        "\n",
        "print(f\"학습 데이터 shape: {X_train.shape}\")\n",
        "print(f\"검증 데이터 shape: {X_val.shape}\")\n",
        "print(f\"테스트 데이터 shape: {X_test.shape}\\n\")\n",
        "\n",
        "# 정규화: StandardScaler 사용\n",
        "# Scaler는 2D 데이터만 받으므로, 3D 데이터를 2D로 변환 후 다시 3D로 복원해야 함\n",
        "# 원본 shape: (샘플 수, 피처 수, 윈도우 크기)\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# train 데이터 기준으로 scaler 학습\n",
        "nsamples, nfeatures, nsteps = X_train.shape\n",
        "X_train_2d = X_train.reshape(nsamples, -1)\n",
        "scaler.fit(X_train_2d)\n",
        "\n",
        "# 모든 데이터에 scaler 적용\n",
        "X_train_scaled_2d = scaler.transform(X_train_2d)\n",
        "X_val_scaled_2d = scaler.transform(X_val.reshape(X_val.shape[0], -1))\n",
        "X_test_scaled_2d = scaler.transform(X_test.reshape(X_test.shape[0], -1))\n",
        "\n",
        "# 다시 원래의 3D shape으로 복원\n",
        "X_train_scaled = X_train_scaled_2d.reshape(nsamples, nfeatures, nsteps)\n",
        "X_val_scaled = X_val_scaled_2d.reshape(X_val.shape[0], nfeatures, nsteps)\n",
        "X_test_scaled = X_test_scaled_2d.reshape(X_test.shape[0], nfeatures, nsteps)\n",
        "print(\"정규화 완료\\n\")\n",
        "\n",
        "\n",
        "# --- 5. 모델 입력 형태(PyTorch Tensor)로 변환 ---\n",
        "print(\"--- PyTorch 텐서로 변환 ---\")\n",
        "# (샘플 수, 채널, 높이, 너비) -> (샘플 수, 1, 피처 수, 윈도우 크기)\n",
        "# unsqueeze(1)을 사용해 채널 차원(C=1)을 추가\n",
        "train_final = torch.from_numpy(X_train_scaled).float().unsqueeze(1)\n",
        "val_final = torch.from_numpy(X_val_scaled).float().unsqueeze(1)\n",
        "test_final = torch.from_numpy(X_test_scaled).float().unsqueeze(1)\n",
        "\n",
        "# 레이블도 텐서로 변환\n",
        "y_train_final = torch.from_numpy(y_train).long()\n",
        "y_val_final = torch.from_numpy(y_val).long()\n",
        "y_test_final = torch.from_numpy(y_test).long()\n",
        "\n"
      ],
      "metadata": {
        "id": "MtEJ2u8TjmPl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "67cd14e8-13df-4036-dbd0-618641eed5b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 데이터 준비 ---\n",
            "--- 슬라이딩 윈도우 적용 ---\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'labels' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3462248456.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# 해당 조각의 레이블 결정 (윈도우의 마지막 시점 레이블 사용)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mcurrent_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mwindow_size\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0msegment_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'labels' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"최종 학습 데이터 shape: {train_final.shape}\")\n",
        "print(f\"최종 검증 데이터 shape: {val_final.shape}\")\n",
        "print(f\"최종 테스트 데이터 shape: {test_final.shape}\")"
      ],
      "metadata": {
        "id": "DcpsabxevrET"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}